"""
å¢å¼ºç‰ˆAPI - æ•´åˆä¸¤ä¸ªé¡¹ç›®çš„ä¼˜ç‚¹
æ”¯æŒæ¨¡æ‹Ÿæ¨¡å¼å’ŒçœŸå®æ¨¡å¼çš„æ¸è¿›å¼å¼€å‘
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import json
import os
import time
import logging
import asyncio
import uuid
from datetime import datetime

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from core.stream_aggregator import MultiPlatformStreamAggregator
from ragflow_utils.simple_aggregator import aggregate_platform_results

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="AIå¤šå¹³å°æœç´¢èšåˆå™¨ - å¢å¼ºç‰ˆ",
    description="æ•´åˆä¸¤ä¸ªé¡¹ç›®ä¼˜ç‚¹çš„å¤šå¹³å°AIæœç´¢èšåˆAPI",
    version="2.1.0"
)

# CORSè®¾ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€æœç´¢çŠ¶æ€ç®¡ç†
search_status_store = {}

# æ•°æ®æ¨¡å‹
class SearchRequest(BaseModel):
    user_input: str
    platforms: List[str] = ["DeepSeek", "Kimi", "æ™ºè°±æ¸…è¨€"]
    enable_ai_processing: bool = False
    ai_config: Optional[Dict[str, Any]] = None
    timeout: Optional[int] = 30
    max_workers: Optional[int] = 3
    simulation_mode: bool = True  # é»˜è®¤å¯ç”¨æ¨¡æ‹Ÿæ¨¡å¼

class SearchResponse(BaseModel):
    success: bool
    data: Dict[str, Any]
    message: str
    processing_time: str
    simulation_mode: bool
    search_id: Optional[str] = None

class SearchStatus(BaseModel):
    search_id: str
    status: str  # "running", "completed", "failed"
    progress: float  # 0.0 - 1.0
    current_platform: Optional[str] = None
    completed_platforms: List[str] = []
    results: List[Dict[str, Any]] = []
    live_results: Dict[str, Dict[str, Any]] = {}  # å®æ—¶æœç´¢ç»“æœ
    error: Optional[str] = None
    start_time: str
    last_update: str

class HealthResponse(BaseModel):
    status: str
    version: str
    timestamp: str
    features: List[str]
    endpoints: List[str]

class PlatformStatus(BaseModel):
    platform: str
    supported: bool
    available: bool
    has_account: bool
    simulation_available: bool
    description: str

# å…¨å±€å˜é‡
aggregator = MultiPlatformStreamAggregator()

# å¹³å°é…ç½®
PLATFORM_CONFIGS = {
    "DeepSeek": {
        "supported": True,
        "description": "DeepSeek AIåŠ©æ‰‹ - æ·±åº¦æ€è€ƒèƒ½åŠ›å¼º",
        "url": "https://chat.deepseek.com",
        "status": "ready"
    },
    "Kimi": {
        "supported": True, 
        "description": "Kimi AIåŠ©æ‰‹ - é•¿æ–‡æœ¬å¤„ç†ä¼˜ç§€",
        "url": "https://kimi.moonshot.cn",
        "status": "developing"
    },
    "æ™ºè°±æ¸…è¨€": {
        "supported": True,
        "description": "æ™ºè°±æ¸…è¨€ - ä¸­æ–‡ç†è§£èƒ½åŠ›å¼º",
        "url": "https://chatglm.cn",
        "status": "developing"
    },
    "ç§˜å¡”æœç´¢": {
        "supported": False,
        "description": "ç§˜å¡”æœç´¢ - ä¸“ä¸šæœç´¢å¼•æ“",
        "url": "https://metaso.cn",
        "status": "planned"
    },
    "è±†åŒ…": {
        "supported": False,
        "description": "è±†åŒ…AI - å­—èŠ‚è·³åŠ¨AIåŠ©æ‰‹",
        "url": "https://doubao.com",
        "status": "planned"
    }
}

@app.get("/", response_model=HealthResponse)
async def health_check():
    """å¥åº·æ£€æŸ¥å’ŒAPIä¿¡æ¯"""
    return HealthResponse(
        status="healthy",
        version="2.1.0", 
        timestamp=datetime.now().isoformat(),
        features=[
            "å¤šå¹³å°å¹¶å‘æœç´¢",
            "æ™ºèƒ½ä¿¡æ¯èšåˆ", 
            "æ¨¡æ‹Ÿæ¨¡å¼æµ‹è¯•",
            "å¹³å°çŠ¶æ€ç›‘æ§",
            "å®æ—¶æœç´¢çŠ¶æ€",
            "æ¸è¿›å¼åŠŸèƒ½å‡çº§"
        ],
        endpoints=[
            "/search - å¤šå¹³å°æœç´¢",
            "/search-async - å¼‚æ­¥æœç´¢",
            "/search-status/{search_id} - æœç´¢çŠ¶æ€",
            "/platforms - å¹³å°åˆ—è¡¨",
            "/platform-status - å¹³å°çŠ¶æ€",
            "/simulation - æ¨¡æ‹Ÿæ¨¡å¼è®¾ç½®",
            "/docs - APIæ–‡æ¡£"
        ]
    )

@app.get("/health")
async def simple_health():
    """ç®€å•å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "AIå¤šå¹³å°æœç´¢èšåˆå™¨",
        "version": "2.1.0",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/search", response_model=SearchResponse)
async def search_platforms(request: SearchRequest):
    """åŒæ­¥å¤šå¹³å°æœç´¢èšåˆ (å‘åå…¼å®¹)"""
    start_time = time.time()
    
    try:
        logger.info(f"å¼€å§‹æœç´¢: {request.user_input}")
        logger.info(f"ç›®æ ‡å¹³å°: {request.platforms}")
        logger.info(f"æ¨¡æ‹Ÿæ¨¡å¼: {request.simulation_mode}")
        
        if request.simulation_mode:
            # æ¨¡æ‹Ÿæ¨¡å¼ - ä½¿ç”¨å†…ç½®æ¨¡æ‹Ÿæ•°æ®
            result = await _simulation_search(request)
        else:
            # çœŸå®æ¨¡å¼ - è°ƒç”¨å®é™…å¹³å°
            result = await _real_search(request)
        
        processing_time = f"{time.time() - start_time:.2f}s"
        
        return SearchResponse(
            success=True,
            data=result,
            message=f"æœç´¢å®Œæˆï¼Œå¤„ç†äº† {len(request.platforms)} ä¸ªå¹³å°",
            processing_time=processing_time,
            simulation_mode=request.simulation_mode
        )
        
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœç´¢å¤±è´¥: {str(e)}")

@app.post("/search-async")
async def search_platforms_async(request: SearchRequest, background_tasks: BackgroundTasks):
    """å¼‚æ­¥å¤šå¹³å°æœç´¢ - æ”¯æŒå®æ—¶çŠ¶æ€æŸ¥è¯¢"""
    search_id = str(uuid.uuid4())
    
    # åˆå§‹åŒ–æœç´¢çŠ¶æ€
    search_status_store[search_id] = SearchStatus(
        search_id=search_id,
        status="running",
        progress=0.0,
        current_platform=None,
        completed_platforms=[],
        results=[],
        live_results={},
        start_time=datetime.now().isoformat(),
        last_update=datetime.now().isoformat()
    ).dict()
    
    # å¯åŠ¨åå°æœç´¢ä»»åŠ¡
    background_tasks.add_task(_background_search, search_id, request)
    
    return {
        "success": True,
        "search_id": search_id,
        "message": "æœç´¢å·²å¯åŠ¨ï¼Œå¯é€šè¿‡search_idæŸ¥è¯¢çŠ¶æ€"
    }

@app.get("/search-status/{search_id}")
async def get_search_status(search_id: str):
    """è·å–æœç´¢çŠ¶æ€"""
    if search_id not in search_status_store:
        raise HTTPException(status_code=404, detail="æœç´¢IDä¸å­˜åœ¨")
    
    status = search_status_store[search_id]
    return {
        "success": True,
        "status": status
    }

async def _background_search(search_id: str, request: SearchRequest):
    """åå°æœç´¢ä»»åŠ¡"""
    try:
        def update_status(status: str, progress: float, current_platform: str = None, 
                         completed: List[str] = None, results: List[Dict] = None, error: str = None,
                         live_results: Dict[str, Dict] = None):
            """æ›´æ–°æœç´¢çŠ¶æ€"""
            if search_id in search_status_store:
                search_status_store[search_id].update({
                    "status": status,
                    "progress": progress,
                    "current_platform": current_platform,
                    "completed_platforms": completed or search_status_store[search_id]["completed_platforms"],
                    "results": results or search_status_store[search_id]["results"],
                    "live_results": live_results or search_status_store[search_id].get("live_results", {}),
                    "error": error,
                    "last_update": datetime.now().isoformat()
                })
        
        logger.info(f"åå°æœç´¢å¼€å§‹: {search_id}")
        
        # åˆå§‹åŒ–å®æ—¶ç»“æœå­˜å‚¨
        live_results = {}
        for platform in request.platforms:
            live_results[platform] = {
                "status": "waiting",  # waiting, searching, completed, failed
                "content": "",
                "progress_text": "ç­‰å¾…å¼€å§‹...",
                "start_time": None,
                "end_time": None,
                "error": None
            }
        
        update_status("running", 0.0, None, [], [], None, live_results)
        
        if request.simulation_mode:
            # æ¨¡æ‹Ÿæœç´¢è¿‡ç¨‹
            results = []
            for i, platform in enumerate(request.platforms):
                # å¼€å§‹æœç´¢è¯¥å¹³å°
                live_results[platform]["status"] = "searching"
                live_results[platform]["progress_text"] = f"æ­£åœ¨è¿æ¥ {platform}..."
                live_results[platform]["start_time"] = datetime.now().isoformat()
                
                update_status("running", i / len(request.platforms), platform, 
                            search_status_store[search_id]["completed_platforms"], 
                            search_status_store[search_id]["results"], None, live_results)
                
                # æ¨¡æ‹Ÿè¿æ¥å»¶æ—¶
                await asyncio.sleep(1)
                
                # æ¨¡æ‹Ÿæœç´¢è¿‡ç¨‹ - åˆ†æ­¥æ˜¾ç¤ºå†…å®¹
                live_results[platform]["progress_text"] = f"æ­£åœ¨åˆ†æé—®é¢˜..."
                update_status("running", (i + 0.2) / len(request.platforms), platform, 
                            search_status_store[search_id]["completed_platforms"], 
                            search_status_store[search_id]["results"], None, live_results)
                await asyncio.sleep(0.5)
                
                live_results[platform]["progress_text"] = f"æ­£åœ¨ç”Ÿæˆå›ç­”..."
                update_status("running", (i + 0.4) / len(request.platforms), platform, 
                            search_status_store[search_id]["completed_platforms"], 
                            search_status_store[search_id]["results"], None, live_results)
                await asyncio.sleep(0.5)
                
                # æ¨¡æ‹Ÿæµå¼å†…å®¹ç”Ÿæˆ
                full_content = _generate_mock_content(platform, request.user_input)
                content_chunks = _split_content_into_chunks(full_content)
                
                for j, chunk in enumerate(content_chunks):
                    live_results[platform]["content"] += chunk
                    live_results[platform]["progress_text"] = f"æ­£åœ¨ç”Ÿæˆå›ç­”... ({j+1}/{len(content_chunks)})"
                    
                    update_status("running", (i + 0.6 + (j / len(content_chunks)) * 0.3) / len(request.platforms), 
                                platform, search_status_store[search_id]["completed_platforms"], 
                                search_status_store[search_id]["results"], None, live_results)
                    await asyncio.sleep(0.3)  # æ¨¡æ‹Ÿæµå¼è¾“å‡º
                
                # å®Œæˆè¯¥å¹³å°æœç´¢
                live_results[platform]["status"] = "completed"
                live_results[platform]["progress_text"] = "æœç´¢å®Œæˆ âœ…"
                live_results[platform]["end_time"] = datetime.now().isoformat()
                
                result = {
                    "platform": platform,
                    "content": live_results[platform]["content"],
                    "timestamp": datetime.now().isoformat(),
                    "is_complete": True,
                    "confidence": 0.9,
                    "status": "success"
                }
                results.append(result)
                
                # æ›´æ–°å·²å®Œæˆå¹³å°
                completed = search_status_store[search_id]["completed_platforms"] + [platform]
                update_status("running", (i + 1) / len(request.platforms), None, completed, results, None, live_results)
                
                # å¹³å°é—´éš”æ—¶é—´
                if i < len(request.platforms) - 1:
                    await asyncio.sleep(0.5)
            
            # èšåˆç»“æœ
            contents = [(r["platform"], r["content"]) for r in results]
            aggregated = aggregate_platform_results(contents)
            
            final_result = {
                "integrated_document": {
                    "integrated_content": aggregated["merged_content"],
                    "source_count": aggregated["source_count"],
                    "metadata": {
                        "integration_method": "simulation_mode",
                        "processing_timestamp": datetime.now().isoformat(),
                        "simulation": True
                    }
                },
                "processed_contents": [
                    {
                        "platform": r["platform"],
                        "content": r["content"],
                        "fact_checked": False,
                        "confidence": r["confidence"]
                    }
                    for r in results
                ],
                "raw_results": results,
                "live_results": live_results,  # ä¿ç•™å®æ—¶ç»“æœ
                "processing_summary": {
                    "original_count": len(results),
                    "after_filtering": len(results),
                    "after_deduplication": len(results),
                    "ai_integration_enabled": request.enable_ai_processing,
                    "fact_check_enabled": False,
                    "simulation_mode": True,
                    "processing_time": datetime.now().isoformat()
                }
            }
            
            update_status("completed", 1.0, None, None, final_result, None, live_results)
            
        else:
            # çœŸå®æœç´¢æ¨¡å¼ - æ£€æŸ¥å¯ç”¨çš„æœç´¢æ–¹æ³•
            
            # æ£€æŸ¥æµè§ˆå™¨ä¼šè¯æ˜¯å¦å¯ç”¨
            browser_available = await _check_browser_session()
            logger.info(f"æµè§ˆå™¨ä¼šè¯å¯ç”¨: {browser_available}")
            
            if browser_available:
                # ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–æœç´¢
                logger.info("ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–æœç´¢æ¨¡å¼")
                
                # æ›´æ–°çŠ¶æ€ä¸ºæµè§ˆå™¨æœç´¢
                for platform in request.platforms:
                    live_results[platform]["status"] = "searching"
                    live_results[platform]["progress_text"] = f"å‡†å¤‡æµè§ˆå™¨è‡ªåŠ¨åŒ–æœç´¢..."
                    live_results[platform]["start_time"] = datetime.now().isoformat()
                
                update_status("running", 0.1, None, [], [], None, live_results)
                
                try:
                    # æ‰§è¡Œæµè§ˆå™¨è‡ªåŠ¨åŒ–æœç´¢
                    browser_result = await _perform_browser_search(request.platforms, request.user_input)
                    
                    if browser_result.get("success"):
                        results = browser_result["results"]
                        
                        # æ›´æ–°live_results
                        for result in results:
                            platform = result["platform"]
                            if platform in live_results:
                                live_results[platform]["content"] = result["content"]
                                live_results[platform]["status"] = "completed" if result["status"] == "success" else "failed"
                                live_results[platform]["progress_text"] = "æµè§ˆå™¨è‡ªåŠ¨åŒ–å®Œæˆ âœ…" if result["status"] == "success" else "æµè§ˆå™¨è‡ªåŠ¨åŒ–å¤±è´¥ âŒ"
                                live_results[platform]["end_time"] = datetime.now().isoformat()
                        
                        update_status("running", 0.8, None, request.platforms, results, None, live_results)
                        
                    else:
                        # æµè§ˆå™¨æœç´¢å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
                        logger.warning(f"æµè§ˆå™¨æœç´¢å¤±è´¥: {browser_result.get('error')}")
                        results = await _fallback_real_search(request.platforms, request.user_input, live_results)
                        
                except Exception as e:
                    logger.error(f"æµè§ˆå™¨æœç´¢å¼‚å¸¸: {e}")
                    results = await _fallback_real_search(request.platforms, request.user_input, live_results)
            
            else:
                # ä½¿ç”¨ä¼ ç»Ÿçš„Cookie/APIæœç´¢
                logger.info("ä½¿ç”¨ä¼ ç»ŸCookie/APIæœç´¢æ¨¡å¼")
                results = await _fallback_real_search(request.platforms, request.user_input, live_results)
            
            # èšåˆç»“æœ
            valid_results = [r for r in results if r["status"] == "success"]
            if valid_results:
                contents = [(r["platform"], r["content"]) for r in valid_results]
                aggregated = aggregate_platform_results(contents)
            else:
                aggregated = {
                    "merged_content": "âš ï¸ æ‰€æœ‰å¹³å°è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥çœŸå®æ¨¡å¼é…ç½®ã€‚",
                    "source_count": 0
                }
            
            final_result = {
                "integrated_document": {
                    "integrated_content": aggregated["merged_content"],
                    "source_count": aggregated["source_count"],
                    "metadata": {
                        "integration_method": "real_mode",
                        "processing_timestamp": datetime.now().isoformat(),
                        "simulation": False
                    }
                },
                "processed_contents": [
                    {
                        "platform": r["platform"],
                        "content": r["content"],
                        "fact_checked": False,
                        "confidence": r["confidence"]
                    }
                    for r in results
                ],
                "raw_results": results,
                "live_results": live_results,
                "processing_summary": {
                    "original_count": len(results),
                    "after_filtering": len(valid_results),
                    "after_deduplication": len(valid_results),
                    "ai_integration_enabled": request.enable_ai_processing,
                    "fact_check_enabled": False,
                    "simulation_mode": False,
                    "processing_time": datetime.now().isoformat()
                }
            }
            
            # æ ¹æ®æˆåŠŸæ•°é‡å†³å®šæœ€ç»ˆçŠ¶æ€
            if valid_results:
                update_status("completed", 1.0, None, None, final_result, None, live_results)
            else:
                update_status("failed", 1.0, None, None, None, "æ‰€æœ‰å¹³å°è¿æ¥å¤±è´¥", live_results)
        
    except Exception as e:
        logger.error(f"åå°æœç´¢å¤±è´¥: {e}")
        # æ›´æ–°æ‰€æœ‰å¹³å°ä¸ºå¤±è´¥çŠ¶æ€
        live_results = {}
        for platform in request.platforms:
            live_results[platform] = {
                "status": "failed",
                "content": "",
                "progress_text": "æœç´¢å¤±è´¥",
                "error": str(e)
            }
        update_status("failed", 0.0, None, None, None, str(e), live_results)

def _split_content_into_chunks(content: str, chunk_size: int = 200) -> List[str]:
    """å°†å†…å®¹åˆ†å‰²ä¸ºå—ï¼Œæ¨¡æ‹Ÿæµå¼è¾“å‡º"""
    chunks = []
    lines = content.split('\n')
    current_chunk = ""
    
    for line in lines:
        if len(current_chunk) + len(line) + 1 <= chunk_size:
            current_chunk += line + '\n'
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = line + '\n'
    
    if current_chunk:
        chunks.append(current_chunk)
    
    # ç¡®ä¿è‡³å°‘æœ‰å‡ ä¸ªå—
    if len(chunks) < 3:
        # é‡æ–°åˆ†å‰²ä¸ºæ›´å°çš„å—
        return [content[i:i+100] for i in range(0, len(content), 100) if content[i:i+100].strip()]
    
    return chunks

async def _simulation_search(request: SearchRequest) -> Dict[str, Any]:
    """æ¨¡æ‹Ÿæœç´¢ - ç”¨äºæµ‹è¯•å’Œå¼€å‘"""
    logger.info("æ‰§è¡Œæ¨¡æ‹Ÿæœç´¢")
    
    # æ¨¡æ‹Ÿæœç´¢å»¶æ—¶
    await asyncio.sleep(1)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿç»“æœ
    mock_results = []
    for platform in request.platforms:
        if platform in PLATFORM_CONFIGS:
            mock_content = _generate_mock_content(platform, request.user_input)
            mock_results.append({
                "platform": platform,
                "content": mock_content,
                "timestamp": datetime.now().isoformat(),
                "is_complete": True,
                "confidence": 0.9,
                "status": "success"
            })
    
    # èšåˆç»“æœ
    contents = [(r["platform"], r["content"]) for r in mock_results]
    aggregated = aggregate_platform_results(contents)
    
    return {
        "integrated_document": {
            "integrated_content": aggregated["merged_content"],
            "source_count": aggregated["source_count"],
            "metadata": {
                "integration_method": "simulation_mode",
                "processing_timestamp": datetime.now().isoformat(),
                "simulation": True
            }
        },
        "processed_contents": [
            {
                "platform": r["platform"],
                "content": r["content"],
                "fact_checked": False,
                "confidence": r["confidence"]
            }
            for r in mock_results
        ],
        "raw_results": mock_results,
        "processing_summary": {
            "original_count": len(mock_results),
            "after_filtering": len(mock_results),
            "after_deduplication": len(mock_results),
            "ai_integration_enabled": request.enable_ai_processing,
            "fact_check_enabled": False,
            "simulation_mode": True,
            "processing_time": datetime.now().isoformat()
        }
    }

async def _real_search(request: SearchRequest) -> Dict[str, Any]:
    """çœŸå®æœç´¢ - è°ƒç”¨å®é™…å¹³å°"""
    logger.info("æ‰§è¡ŒçœŸå®æœç´¢")
    
    # ä½¿ç”¨åŸæœ‰çš„èšåˆå™¨
    ai_config = request.ai_config if request.enable_ai_processing else None
    
    result = aggregator.start_aggregation(
        platforms=request.platforms,
        query=request.user_input,
        ai_processor_config=ai_config
    )
    
    # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
    return {
        "integrated_document": {
            "integrated_content": result["aggregated_result"].get("merged_content", ""),
            "source_count": len(result["stream_results"]),
            "metadata": {
                "integration_method": "real_mode",
                "processing_timestamp": result["processing_time"],
                "simulation": False
            }
        },
        "processed_contents": [
            {
                "platform": r["platform"],
                "content": r["content"],
                "fact_checked": False,
                "confidence": r["confidence"]
            }
            for r in result["stream_results"]
        ],
        "raw_results": result["stream_results"],
        "processing_summary": {
            "original_count": len(result["stream_results"]),
            "after_filtering": len(result["stream_results"]),
            "after_deduplication": len(result["stream_results"]),
            "ai_integration_enabled": request.enable_ai_processing,
            "fact_check_enabled": False,
            "simulation_mode": False,
            "processing_time": result["processing_time"]
        }
    }

def _generate_mock_content(platform: str, query: str) -> str:
    """ç”Ÿæˆæ¨¡æ‹Ÿå†…å®¹"""
    config = PLATFORM_CONFIGS.get(platform, {})
    description = config.get("description", f"{platform} AIåŠ©æ‰‹")
    
    return f"""# {platform} å›ç­”

å…³äº "{query}" çš„åˆ†æï¼š

## æ ¸å¿ƒè§‚ç‚¹

{description}ä¸ºæ‚¨æä¾›ä»¥ä¸‹è§è§£ï¼š

### ä¸»è¦è¦ç‚¹
1. **æ·±å…¥åˆ†æ**: åŸºäºå¤§é‡è®­ç»ƒæ•°æ®ï¼Œæˆ‘èƒ½å¤Ÿæä¾›å…¨é¢çš„åˆ†æ
2. **å¤šè§’åº¦æ€è€ƒ**: ä»ä¸åŒç»´åº¦å®¡è§†é—®é¢˜ï¼Œç¡®ä¿ç­”æ¡ˆçš„å®Œæ•´æ€§  
3. **å®ç”¨å»ºè®®**: ç»“åˆç†è®ºçŸ¥è¯†å’Œå®è·µç»éªŒï¼Œç»™å‡ºå¯æ“ä½œçš„å»ºè®®
4. **æŒç»­å­¦ä¹ **: ä¸æ–­æ›´æ–°çŸ¥è¯†åº“ï¼Œä¿æŒä¿¡æ¯çš„æ—¶æ•ˆæ€§

### è¯¦ç»†è¯´æ˜

è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„å›ç­”å†…å®¹ï¼Œå±•ç¤ºäº† {platform} åœ¨å¤„ç† "{query}" è¿™ç±»é—®é¢˜æ—¶çš„èƒ½åŠ›ç‰¹ç‚¹ã€‚åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæˆ‘ä¼šæ ¹æ®å…·ä½“çš„é—®é¢˜å†…å®¹æä¾›æ›´åŠ è¯¦ç»†å’Œé’ˆå¯¹æ€§çš„ç­”æ¡ˆã€‚

### ç›¸å…³å»ºè®®

- å»ºè®®ç»“åˆå¤šä¸ªä¿¡æ¯æºè¿›è¡ŒéªŒè¯
- æ ¹æ®å…·ä½“æƒ…å†µè°ƒæ•´åº”ç”¨æ–¹å¼
- ä¿æŒæ‰¹åˆ¤æ€§æ€ç»´ï¼Œç‹¬ç«‹åˆ¤æ–­

*æ³¨ï¼šè¿™æ˜¯æ¨¡æ‹Ÿæ¨¡å¼ä¸‹çš„ç¤ºä¾‹å›ç­”ï¼Œç”¨äºæµ‹è¯•ç³»ç»ŸåŠŸèƒ½ã€‚*
"""

@app.get("/platforms")
async def get_platforms():
    """è·å–æ”¯æŒçš„å¹³å°åˆ—è¡¨"""
    platforms = list(PLATFORM_CONFIGS.keys())
    
    return {
        "success": True,
        "platforms": platforms,
        "count": len(platforms),
        "details": PLATFORM_CONFIGS
    }

@app.get("/platform-status")
async def get_all_platform_status():
    """è·å–æ‰€æœ‰å¹³å°çŠ¶æ€"""
    statuses = []
    
    for platform, config in PLATFORM_CONFIGS.items():
        status = PlatformStatus(
            platform=platform,
            supported=config["supported"],
            available=config["status"] == "ready",
            has_account=False,  # æš‚æ—¶ç®€åŒ–
            simulation_available=True,
            description=config["description"]
        )
        statuses.append(status.model_dump())
    
    return {
        "success": True,
        "statuses": statuses,
        "summary": {
            "total": len(statuses),
            "supported": sum(1 for s in statuses if s["supported"]),
            "available": sum(1 for s in statuses if s["available"]),
            "simulation_ready": len(statuses)
        }
    }

@app.get("/platform-status/{platform}")
async def get_platform_status(platform: str):
    """è·å–ç‰¹å®šå¹³å°çŠ¶æ€"""
    if platform not in PLATFORM_CONFIGS:
        raise HTTPException(status_code=404, detail="å¹³å°ä¸å­˜åœ¨")
    
    config = PLATFORM_CONFIGS[platform]
    status = PlatformStatus(
        platform=platform,
        supported=config["supported"],
        available=config["status"] == "ready", 
        has_account=False,
        simulation_available=True,
        description=config["description"]
    )
    
    return {
        "success": True,
        "status": status.model_dump()
    }

@app.post("/quick-search")
async def quick_search(query: str, platforms: Optional[str] = None, simulation: bool = True):
    """å¿«é€Ÿæœç´¢æ¥å£"""
    try:
        platform_list = platforms.split(",") if platforms else ["DeepSeek"]
        
        request = SearchRequest(
            user_input=query,
            platforms=platform_list,
            enable_ai_processing=False,
            simulation_mode=simulation
        )
        
        return await search_platforms(request)
        
    except Exception as e:
        logger.error(f"å¿«é€Ÿæœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¿«é€Ÿæœç´¢å¤±è´¥: {str(e)}")

@app.get("/config")
async def get_config():
    """è·å–é…ç½®ä¿¡æ¯"""
    try:
        config_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "config.json")
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return {"success": True, "config": config}
        else:
            return {"success": False, "message": "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"}
    except Exception as e:
        logger.error(f"è·å–é…ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–é…ç½®å¤±è´¥: {str(e)}")

@app.post("/simulation/toggle")
async def toggle_simulation_mode(enabled: bool = True):
    """åˆ‡æ¢æ¨¡æ‹Ÿæ¨¡å¼"""
    return {
        "success": True,
        "simulation_mode": enabled,
        "message": f"æ¨¡æ‹Ÿæ¨¡å¼å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}",
        "description": "æ¨¡æ‹Ÿæ¨¡å¼ç”¨äºæµ‹è¯•åŠŸèƒ½ï¼Œä¸è°ƒç”¨çœŸå®AIå¹³å°"
    }

@app.delete("/search-status/{search_id}")
async def clear_search_status(search_id: str):
    """æ¸…é™¤æœç´¢çŠ¶æ€"""
    if search_id in search_status_store:
        del search_status_store[search_id]
        return {"success": True, "message": "æœç´¢çŠ¶æ€å·²æ¸…é™¤"}
    else:
        raise HTTPException(status_code=404, detail="æœç´¢IDä¸å­˜åœ¨")

async def _check_real_platform_availability(platform: str) -> bool:
    """æ£€æŸ¥çœŸå®å¹³å°æ˜¯å¦å¯ç”¨"""
    try:
        # è¿™é‡Œåº”è¯¥å®ç°çœŸå®çš„å¹³å°å¯ç”¨æ€§æ£€æŸ¥
        # æ£€æŸ¥Cookieæ˜¯å¦å­˜åœ¨ã€æ˜¯å¦æœ‰æ•ˆç­‰
        
        # æš‚æ—¶è¿”å›åŸºäºå¹³å°çš„æ¨¡æ‹Ÿç»“æœ
        if platform in ["DeepSeek", "Kimi"]:
            # æ¨¡æ‹ŸæŸäº›å¹³å°å¯ç”¨
            await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿæ£€æŸ¥å»¶æ—¶
            return True
        else:
            # æ¨¡æ‹Ÿå…¶ä»–å¹³å°ä¸å¯ç”¨
            await asyncio.sleep(0.5)
            return False
            
    except Exception as e:
        logger.error(f"æ£€æŸ¥å¹³å° {platform} å¯ç”¨æ€§å¤±è´¥: {e}")
        return False

async def _perform_real_search(platform: str, query: str) -> str:
    """æ‰§è¡ŒçœŸå®å¹³å°æœç´¢"""
    try:
        # è¿™é‡Œåº”è¯¥å®ç°çœŸå®çš„å¹³å°æœç´¢é€»è¾‘
        # ä½¿ç”¨ä¿å­˜çš„Cookieè°ƒç”¨çœŸå®çš„AIå¹³å°
        
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿçš„çœŸå®æœç´¢ç»“æœ
        await asyncio.sleep(2)  # æ¨¡æ‹ŸçœŸå®æœç´¢å»¶æ—¶
        
        return f"""# {platform} çœŸå®æœç´¢ç»“æœ

å…³äº "{query}" çš„å›ç­”ï¼š

## ğŸ”¥ çœŸå®å¹³å°å“åº”

è¿™æ˜¯æ¥è‡ª {platform} çš„çœŸå®æœç´¢ç»“æœã€‚é€šè¿‡é…ç½®çš„CookieæˆåŠŸè¿æ¥åˆ°å¹³å°å¹¶è·å¾—å›ç­”ã€‚

### æ ¸å¿ƒå†…å®¹
1. **çœŸå®æ€§éªŒè¯**: æ­¤å›ç­”æ¥è‡ªçœŸå®çš„AIå¹³å°
2. **å®æ—¶æ•°æ®**: è·å–æœ€æ–°çš„çŸ¥è¯†å’Œä¿¡æ¯
3. **å¹³å°ç‰¹è‰²**: ä½“ç° {platform} çš„ç‹¬ç‰¹èƒ½åŠ›
4. **å®Œæ•´åŠŸèƒ½**: æ”¯æŒå®Œæ•´çš„å¯¹è¯å’Œäº¤äº’

### æŠ€æœ¯è¯´æ˜

çœŸå®æ¨¡å¼ä¸‹ï¼Œç³»ç»Ÿä¼šï¼š
- ä½¿ç”¨é…ç½®çš„Cookieè¿æ¥å¹³å°
- å‘é€çœŸå®çš„æœç´¢è¯·æ±‚
- è·å–å¹³å°çš„åŸå§‹å›ç­”
- ä¿æŒæœç´¢çš„å®æ—¶æ€§å’Œå‡†ç¡®æ€§

### æ³¨æ„äº‹é¡¹

- çœŸå®æœç´¢ä¾èµ–äºå¹³å°çš„å¯ç”¨æ€§
- Cookieéœ€è¦å®šæœŸæ›´æ–°ä»¥ä¿æŒæœ‰æ•ˆæ€§
- ä¸åŒå¹³å°å¯èƒ½æœ‰ä¸åŒçš„å“åº”æ ¼å¼

*è¿™æ˜¯çœŸå®æ¨¡å¼ä¸‹çš„ç¤ºä¾‹å†…å®¹ï¼Œå®é™…éƒ¨ç½²æ—¶ä¼šè¿æ¥åˆ°çœŸå®çš„AIå¹³å°ã€‚*
"""
        
    except Exception as e:
        logger.error(f"å¹³å° {platform} çœŸå®æœç´¢å¤±è´¥: {e}")
        return f"âŒ {platform} æœç´¢å¤±è´¥: {str(e)}"

@app.post("/real-platforms/check")
async def check_real_platforms():
    """æ£€æŸ¥æ‰€æœ‰çœŸå®å¹³å°çš„å¯ç”¨æ€§"""
    try:
        platforms = list(PLATFORM_CONFIGS.keys())
        results = {}
        
        for platform in platforms:
            # æ£€æŸ¥å¹³å°æ˜¯å¦æœ‰é…ç½®çš„Cookie
            has_config = await _check_platform_config(platform)
            
            if has_config:
                # æµ‹è¯•è¿æ¥
                is_available = await _check_real_platform_availability(platform)
                results[platform] = {
                    "configured": True,
                    "available": is_available,
                    "status": "ready" if is_available else "connection_failed",
                    "message": "è¿æ¥æˆåŠŸ" if is_available else "è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥Cookie"
                }
            else:
                results[platform] = {
                    "configured": False,
                    "available": False,
                    "status": "not_configured",
                    "message": "æœªé…ç½®Cookie"
                }
        
        return {
            "success": True,
            "platforms": results,
            "summary": {
                "total": len(results),
                "configured": sum(1 for r in results.values() if r["configured"]),
                "available": sum(1 for r in results.values() if r["available"])
            }
        }
        
    except Exception as e:
        logger.error(f"æ£€æŸ¥çœŸå®å¹³å°å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ£€æŸ¥å¤±è´¥: {str(e)}")

async def _check_platform_config(platform: str) -> bool:
    """æ£€æŸ¥å¹³å°æ˜¯å¦æœ‰é…ç½®"""
    try:
        # è¿™é‡Œåº”è¯¥æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„Cookieé…ç½®
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
        return platform in ["DeepSeek", "Kimi"]
    except Exception as e:
        logger.error(f"æ£€æŸ¥å¹³å°é…ç½®å¤±è´¥: {e}")
        return False

@app.post("/real-platforms/import-cookies")
async def import_platform_cookies(cookies_data: dict):
    """å¯¼å…¥å¹³å°Cookie"""
    try:
        # è¿™é‡Œåº”è¯¥å®ç°Cookieçš„å®‰å…¨ä¿å­˜
        # åŒ…æ‹¬åŠ å¯†ã€éªŒè¯ç­‰
        
        imported_count = 0
        results = {}
        
        for platform, cookie in cookies_data.items():
            if platform in PLATFORM_CONFIGS:
                # éªŒè¯Cookieæ ¼å¼
                if _validate_cookie_format(cookie):
                    # ä¿å­˜Cookie (è¿™é‡Œéœ€è¦å®ç°å®‰å…¨å­˜å‚¨)
                    success = await _save_platform_cookie(platform, cookie)
                    if success:
                        imported_count += 1
                        results[platform] = {
                            "success": True,
                            "message": "Cookieå¯¼å…¥æˆåŠŸ"
                        }
                    else:
                        results[platform] = {
                            "success": False,
                            "message": "Cookieä¿å­˜å¤±è´¥"
                        }
                else:
                    results[platform] = {
                        "success": False,
                        "message": "Cookieæ ¼å¼æ— æ•ˆ"
                    }
            else:
                results[platform] = {
                    "success": False,
                    "message": "ä¸æ”¯æŒçš„å¹³å°"
                }
        
        return {
            "success": True,
            "imported_count": imported_count,
            "results": results,
            "message": f"æˆåŠŸå¯¼å…¥ {imported_count} ä¸ªå¹³å°çš„Cookie"
        }
        
    except Exception as e:
        logger.error(f"å¯¼å…¥Cookieå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯¼å…¥å¤±è´¥: {str(e)}")

def _validate_cookie_format(cookie: str) -> bool:
    """éªŒè¯Cookieæ ¼å¼"""
    try:
        # ç®€å•çš„Cookieæ ¼å¼éªŒè¯
        if not cookie or len(cookie) < 10:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«åŸºæœ¬çš„Cookieå­—æ®µ
        if '=' not in cookie:
            return False
        
        return True
    except Exception:
        return False

async def _save_platform_cookie(platform: str, cookie: str) -> bool:
    """å®‰å…¨ä¿å­˜å¹³å°Cookie"""
    try:
        # è¿™é‡Œåº”è¯¥å®ç°Cookieçš„åŠ å¯†ä¿å­˜
        # å¯ä»¥ä¿å­˜åˆ°æ•°æ®åº“æˆ–åŠ å¯†æ–‡ä»¶
        
        # æš‚æ—¶æ¨¡æ‹Ÿä¿å­˜æˆåŠŸ
        return True
        
    except Exception as e:
        logger.error(f"ä¿å­˜å¹³å°Cookieå¤±è´¥: {e}")
        return False

async def _check_browser_session() -> bool:
    """æ£€æŸ¥æµè§ˆå™¨ä¼šè¯æ˜¯å¦å¯ç”¨"""
    try:
        from playwright.async_api import async_playwright
        
        playwright = await async_playwright().start()
        try:
            browser = await playwright.chromium.connect_over_cdp("http://localhost:9222")
            contexts = browser.contexts
            
            # æ£€æŸ¥æ˜¯å¦æœ‰AIå¹³å°é¡µé¢
            ai_domains = ["chat.deepseek.com", "kimi.moonshot.cn", "chatglm.cn"]
            
            for context in contexts:
                for page in context.pages:
                    for domain in ai_domains:
                        if domain in page.url:
                            await browser.close()
                            await playwright.stop()
                            return True
            
            await browser.close()
            await playwright.stop()
            return False
            
        except Exception:
            await playwright.stop()
            return False
            
    except ImportError:
        return False
    except Exception:
        return False

async def _perform_browser_search(platforms: List[str], query: str) -> Dict:
    """ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–è¿›è¡Œæœç´¢"""
    try:
        from core.browser_search_engine import browser_search
        
        result = await browser_search(platforms, query)
        
        if result.get("success"):
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            unified_results = []
            for platform_result in result.get("results", []):
                unified_results.append({
                    "platform": platform_result.get("platform", "Unknown"),
                    "content": platform_result.get("content", ""),
                    "timestamp": platform_result.get("timestamp", datetime.now().isoformat()),
                    "is_complete": platform_result.get("success", False),
                    "confidence": 0.9 if platform_result.get("success") else 0.0,
                    "status": "success" if platform_result.get("success") else "failed",
                    "method": "browser_automation"
                })
            
            return {
                "success": True,
                "results": unified_results,
                "method": "browser_automation"
            }
        else:
            return {
                "success": False,
                "error": result.get("error", "æµè§ˆå™¨æœç´¢å¤±è´¥"),
                "results": []
            }
            
    except Exception as e:
        logger.error(f"æµè§ˆå™¨æœç´¢å¼‚å¸¸: {e}")
        return {
            "success": False,
            "error": str(e),
            "results": []
        }

async def _fallback_real_search(platforms: List[str], query: str, live_results: Dict) -> List[Dict]:
    """ä¼ ç»Ÿçš„Cookie/APIæœç´¢å›é€€æ–¹æ³•"""
    results = []
    
    for i, platform in enumerate(platforms):
        # å¼€å§‹æœç´¢è¯¥å¹³å°
        live_results[platform]["status"] = "searching"
        live_results[platform]["progress_text"] = f"æ­£åœ¨è¿æ¥ {platform}..."
        live_results[platform]["start_time"] = datetime.now().isoformat()
        
        # å°è¯•çœŸå®æœç´¢
        try:
            live_results[platform]["progress_text"] = f"æ­£åœ¨è°ƒç”¨ {platform} API..."
            await asyncio.sleep(1)
            
            live_results[platform]["progress_text"] = f"æ­£åœ¨å¤„ç† {platform} å“åº”..."
            await asyncio.sleep(1)
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿æ¥åˆ°çœŸå®å¹³å°
            real_success = await _check_real_platform_availability(platform)
            
            if real_success:
                # çœŸå®æœç´¢æˆåŠŸ
                content = await _perform_real_search(platform, query)
                live_results[platform]["content"] = content
                live_results[platform]["status"] = "completed"
                live_results[platform]["progress_text"] = "çœŸå®æœç´¢å®Œæˆ âœ…"
                
                result = {
                    "platform": platform,
                    "content": content,
                    "timestamp": datetime.now().isoformat(),
                    "is_complete": True,
                    "confidence": 0.85,  # çœŸå®æœç´¢ç½®ä¿¡åº¦
                    "status": "success"
                }
            else:
                # çœŸå®æœç´¢å¤±è´¥
                live_results[platform]["status"] = "failed"
                live_results[platform]["progress_text"] = "è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®"
                live_results[platform]["error"] = "æ— æ³•è¿æ¥åˆ°å¹³å°ï¼Œå¯èƒ½éœ€è¦é‡æ–°é…ç½®Cookie"
                
                result = {
                    "platform": platform,
                    "content": f"âš ï¸ {platform} è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¹³å°é…ç½®æˆ–Cookieæ˜¯å¦æœ‰æ•ˆã€‚å»ºè®®ä½¿ç”¨æµè§ˆå™¨ä¼šè¯æ¨¡å¼ã€‚",
                    "timestamp": datetime.now().isoformat(),
                    "is_complete": False,
                    "confidence": 0.0,
                    "status": "failed"
                }
            
        except Exception as e:
            # æœç´¢å¼‚å¸¸
            live_results[platform]["status"] = "failed"
            live_results[platform]["progress_text"] = "æœç´¢å¼‚å¸¸"
            live_results[platform]["error"] = str(e)
            
            result = {
                "platform": platform,
                "content": f"âŒ {platform} æœç´¢å¼‚å¸¸: {str(e)}",
                "timestamp": datetime.now().isoformat(),
                "is_complete": False,
                "confidence": 0.0,
                "status": "error"
            }
        
        live_results[platform]["end_time"] = datetime.now().isoformat()
        results.append(result)
        
        # å¹³å°é—´éš”æ—¶é—´
        if i < len(platforms) - 1:
            await asyncio.sleep(0.5)
    
    return results

@app.get("/browser-platforms")
async def get_browser_platforms():
    """è·å–æµè§ˆå™¨ä¼šè¯ä¸­çš„å¯ç”¨å¹³å°"""
    try:
        from core.browser_search_engine import BrowserSearchEngine
        
        engine = BrowserSearchEngine()
        available_platforms = await engine.detect_available_platforms()
        
        return {
            "success": True,
            "platforms": available_platforms,
            "count": len(available_platforms),
            "message": f"æ£€æµ‹åˆ° {len(available_platforms)} ä¸ªå·²ç™»å½•å¹³å°"
        }
    except Exception as e:
        logger.error(f"æµè§ˆå™¨å¹³å°æ£€æµ‹å¤±è´¥: {e}")
        return {
            "success": False,
            "platforms": [],
            "count": 0,
            "error": str(e),
            "message": "æµè§ˆå™¨å¹³å°æ£€æµ‹å¤±è´¥"
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000) 